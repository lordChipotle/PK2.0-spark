{"cells":[{"cell_type":"code","source":["downloaduploadToken = \"dapi6d468a9667263e882d7a258a29e16944\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70f9067d-11fe-472d-9e77-bf46102def28"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Running the Pair-matching Algorithm\n We will be using the Pair-matching Algorithm to conduct type-counting on a PROV document\n This is an introductory notebook to illustrate how pair-matching algorithm works in a Provenance Kernel\n The structure of this notebook:\n1. Converting PROV document to Graphframes dataframes\n2. Perform Type-Counting on Dataframes\n3. Summarize type counting results with a feature vector of respective occurences\n4. Generate a sparse matrix and store the results in DBFS (Databricks File System)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fdbe5d9-80e5-4ad4-9aaa-e92d3e715b09"}}},{"cell_type":"markdown","source":["**Note that, if you are using Databricks Community Edition, there is no support for DBFS. Therefore you can only use our notebooks to perform demonstration on a sample PROV files from the PROV store.**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b22f4890-8aa9-44e8-8343-92759d157878"}}},{"cell_type":"markdown","source":["We will first import all the required packages. Make sure graphframes, prov, pandas, and mllib (although not used in this notebook)packages are installed on your cluster. The scala and spark verision number of graphframe should match your selected Spark version."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e79ae47-0a2e-4743-a3d5-9963c8361c81"}}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport time\nimport functools\nfrom pyspark.sql.functions import col, lit, when\nfrom graphframes import *\nimport pandas as pd\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom pyspark.sql.functions import col\n\n\nfrom itertools import chain\nfrom typing import Dict\nimport requests\nfrom prov.model import ProvDocument\n\nimport json\nimport os\n\n\nfrom pyspark.sql import DataFrame\nfrom prov.model import (\n    ProvDocument,\n    ProvRecord,\n    ProvElement,\n    ProvEntity,\n    ProvActivity,\n    ProvAgent,\n    ProvRelation,\n    PROV_ATTR_ENTITY,\n    PROV_ATTR_ACTIVITY,\n    PROV_ATTR_AGENT,\n    PROV_ATTR_TRIGGER,\n    PROV_ATTR_GENERATED_ENTITY,\n    PROV_ATTR_USED_ENTITY,\n    PROV_ATTR_DELEGATE,\n    PROV_ATTR_RESPONSIBLE,\n    PROV_ATTR_SPECIFIC_ENTITY,\n    PROV_ATTR_GENERAL_ENTITY,\n    PROV_ATTR_ALTERNATE1,\n    PROV_ATTR_ALTERNATE2,\n    PROV_ATTR_COLLECTION,\n    PROV_ATTR_INFORMED,\n    PROV_ATTR_INFORMANT,\n    PROV_ATTR_BUNDLE,\n    PROV_ATTR_PLAN,\n    PROV_ATTR_ENDER,\n    PROV_ATTR_STARTER,\n    ProvBundle,\n)\nINFERRED_ELEMENT_CLASS = {\n    PROV_ATTR_ENTITY: ProvEntity,\n    PROV_ATTR_ACTIVITY: ProvActivity,\n    PROV_ATTR_AGENT: ProvAgent,\n    PROV_ATTR_TRIGGER: ProvEntity,\n    PROV_ATTR_GENERATED_ENTITY: ProvEntity,\n    PROV_ATTR_USED_ENTITY: ProvEntity,\n    PROV_ATTR_DELEGATE: ProvAgent,\n    PROV_ATTR_RESPONSIBLE: ProvAgent,\n    PROV_ATTR_SPECIFIC_ENTITY: ProvEntity,\n    PROV_ATTR_GENERAL_ENTITY: ProvEntity,\n    PROV_ATTR_ALTERNATE1: ProvEntity,\n    PROV_ATTR_ALTERNATE2: ProvEntity,\n    PROV_ATTR_COLLECTION: ProvEntity,\n    PROV_ATTR_INFORMED: ProvActivity,\n    PROV_ATTR_INFORMANT: ProvActivity,\n    PROV_ATTR_BUNDLE: ProvBundle,\n    PROV_ATTR_PLAN: ProvEntity,\n    PROV_ATTR_ENDER: ProvEntity,\n    PROV_ATTR_STARTER: ProvEntity,\n}\n#used for formatting provenance types\nSHORT_NAMES = {\n    \"prov:Entity\": \"ent\",\n    \"prov:Activity\": \"act\",\n    \"prov:Generation\": \"gen\",\n    \"prov:Usage\": \"usd\",\n    \"prov:Communication\": \"wib\",\n    \"prov:Start\": \"wsb\",\n    \"prov:End\": \"web\",\n    \"prov:Invalidation\": \"inv\",\n    \"prov:Derivation\": \"der\",\n    \"prov:Agent\": \"agt\",\n    \"prov:Attribution\": \"att\",\n    \"prov:Association\": \"waw\",\n    \"prov:Delegation\": \"del\",\n    \"prov:Influence\": \"inf\",\n    \"prov:Alternate\": \"alt\",\n    \"prov:Specialization\": \"spe\",\n    \"prov:Mention\": \"men\",\n    \"prov:Membership\": \"mem\",\n}\nprovClassList = [\n    \"prov:Entity\",\n    \"prov:Activity\",\n    \"prov:Generation\",\n    \"prov:Usage\",\n    \"prov:Communication\",\n    \"prov:Start\",\n    \"prov:End\",\n    \"prov:Invalidation\",\n    \"prov_Derivation\",\n    \"prov:Agent\",\n    \"prov:Attribution\",\n    \"prov:Association\",\n    \"prov:Delegation\",\n    \"prov:Influence\",\n    \"prov:Alternate\",\n    \"prov:Specialization\",\n    \"prov:Mention\",\n    \"prov:Membership\",\n]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"282f97a1-103b-459a-9373-d307ed889e8b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Then we use a download_prov_json_document from the prov library to query a PROV file from the PROV store"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fdb1196-6760-4edb-b620-36f4508870a2"}}},{"cell_type":"code","source":["def download_prov_json_document(url: str) -> ProvDocument:\n    # try to download the provided url\n    r = requests.get(url)\n    \n    r.raise_for_status()\n    # no exception so far, we have successfuly downloaded it\n    prov_doc = ProvDocument.deserialize(content=r.text)\n    return prov_doc\n  \n#here we use the Cause of WWI example from the paper\ndocument = download_prov_json_document(\"https://openprovenance.org/store/documents/4141.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62c75a48-01e2-4a48-b7ad-ee6f158877b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["we define a function to convert PROV files to Graphframe dataframes and create a graph from it"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f24253e-c419-4815-9d19-d8bbe677f927"}}},{"cell_type":"code","source":["#This function is inspired by the prov_to_graph()function from prov library: https://github.com/trungdong/prov\ndef prov_to_graphframe(prov_document):\n      unified = prov_document.unified() #unify the information in the PROV document\n      node_map = {}\n      vList = [] #a list to collect all the vertices\n      eList = [] # a list to collect all the edges\n\n      #for loop and collect specific information from PROV element and add them to the vertices list\n      for element in unified.get_records(ProvElement):\n        vList.append(((str(element)),str(element.identifier),SHORT_NAMES[str(element.get_type())],str(element.get_asserted_types())))\n        node_map[element.identifier] = element\n      #similar process but for edges\n      for relation in unified.get_records(ProvRelation):\n              attr_pair_1, attr_pair_2 = relation.formal_attributes[:2]\n              qn1, qn2 = attr_pair_1[1], attr_pair_2[1]\n              if qn1 and qn2:  \n                  try:\n                      if qn1 not in node_map:\n                          node_map[qn1] = INFERRED_ELEMENT_CLASS[attr_pair_1[0]](None, qn1)\n                      if qn2 not in node_map:\n                          node_map[qn2] = INFERRED_ELEMENT_CLASS[attr_pair_2[0]](None, qn2)\n                  except KeyError:\n                      continue  \n                  eList.append((str(node_map[qn1].identifier), str(node_map[qn2].identifier), str(relation),SHORT_NAMES[str(relation.get_type())]))\n      #create a dataframe from the vertices list\n      v = sqlContext.createDataFrame(vList,[\"element\",\"id\",\"type\",\"primitive type\"])\n      #create a dataframe from the edges list\n      e = sqlContext.createDataFrame(eList, [\"src\",\"dst\",\"relation\",\"relation type\"])\n      #create a Graphframe with the two dataframes\n      g= GraphFrame(v, e)\n      return g\ng = prov_to_graphframe(document)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"114ff576-4b36-4180-aaa8-fdb087d14c93"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's take a look at the graphframe object we have just created"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca131d4a-3525-4dee-9598-e39efa8bf261"}}},{"cell_type":"code","source":["g.vertices.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b1cba66-37af-48a1-ac2a-046f61925c0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["agent(ex:Germany, [prov:type='prov:Country'])","ex:Germany","agt","{<QualifiedName: prov:Country>}"],["agent(ex:Ferdinand, [s:Fullname=\"Archduke Franz Ferdinand\", s:Nationality=\"Austro-Hungarian Empire\", prov:type='prov:Person'])","ex:Ferdinand","agt","{<QualifiedName: prov:Person>}"],["agent(ex:Princip, [s:Fullname=\"Gavrilo Princip\", s:Nationality=\"Serbia\", prov:type='prov:Person'])","ex:Princip","agt","{<QualifiedName: prov:Person>}"],["agent(ex:Serbia, [prov:type='prov:Country'])","ex:Serbia","agt","{<QualifiedName: prov:Country>}"],["agent(ex:AustriaHungary, [prov:type='prov:Country'])","ex:AustriaHungary","agt","{<QualifiedName: prov:Country>}"],["activity(ex:send_message, -, -)","ex:send_message","act","set()"],["activity(ex:inspect_annexation, -, -)","ex:inspect_annexation","act","set()"],["activity(ex:declares_wars_onTripleEntente, -, -)","ex:declares_wars_onTripleEntente","act","set()"],["activity(ex:declares_wars_onSerbia, -, -)","ex:declares_wars_onSerbia","act","set()"],["activity(ex:assassinate_Ferdinand, -, -)","ex:assassinate_Ferdinand","act","set()"],["entity(ex:TripleAllianceAgreement, [s:year=\"1882\"])","ex:TripleAllianceAgreement","ent","set()"],["entity(ex:support_from_germany)","ex:support_from_germany","ent","set()"],["entity(ex:beginning_of_WWI, [s:year=\"1914\"])","ex:beginning_of_WWI","ent","set()"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"element","type":"\"string\"","metadata":"{}"},{"name":"id","type":"\"string\"","metadata":"{}"},{"name":"type","type":"\"string\"","metadata":"{}"},{"name":"primitive type","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>element</th><th>id</th><th>type</th><th>primitive type</th></tr></thead><tbody><tr><td>agent(ex:Germany, [prov:type='prov:Country'])</td><td>ex:Germany</td><td>agt</td><td>{<QualifiedName: prov:Country>}</td></tr><tr><td>agent(ex:Ferdinand, [s:Fullname=\"Archduke Franz Ferdinand\", s:Nationality=\"Austro-Hungarian Empire\", prov:type='prov:Person'])</td><td>ex:Ferdinand</td><td>agt</td><td>{<QualifiedName: prov:Person>}</td></tr><tr><td>agent(ex:Princip, [s:Fullname=\"Gavrilo Princip\", s:Nationality=\"Serbia\", prov:type='prov:Person'])</td><td>ex:Princip</td><td>agt</td><td>{<QualifiedName: prov:Person>}</td></tr><tr><td>agent(ex:Serbia, [prov:type='prov:Country'])</td><td>ex:Serbia</td><td>agt</td><td>{<QualifiedName: prov:Country>}</td></tr><tr><td>agent(ex:AustriaHungary, [prov:type='prov:Country'])</td><td>ex:AustriaHungary</td><td>agt</td><td>{<QualifiedName: prov:Country>}</td></tr><tr><td>activity(ex:send_message, -, -)</td><td>ex:send_message</td><td>act</td><td>set()</td></tr><tr><td>activity(ex:inspect_annexation, -, -)</td><td>ex:inspect_annexation</td><td>act</td><td>set()</td></tr><tr><td>activity(ex:declares_wars_onTripleEntente, -, -)</td><td>ex:declares_wars_onTripleEntente</td><td>act</td><td>set()</td></tr><tr><td>activity(ex:declares_wars_onSerbia, -, -)</td><td>ex:declares_wars_onSerbia</td><td>act</td><td>set()</td></tr><tr><td>activity(ex:assassinate_Ferdinand, -, -)</td><td>ex:assassinate_Ferdinand</td><td>act</td><td>set()</td></tr><tr><td>entity(ex:TripleAllianceAgreement, [s:year=\"1882\"])</td><td>ex:TripleAllianceAgreement</td><td>ent</td><td>set()</td></tr><tr><td>entity(ex:support_from_germany)</td><td>ex:support_from_germany</td><td>ent</td><td>set()</td></tr><tr><td>entity(ex:beginning_of_WWI, [s:year=\"1914\"])</td><td>ex:beginning_of_WWI</td><td>ent</td><td>set()</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["g.edges.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3371975-62fa-4b69-908e-a2cb3dd833b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["ex:beginning_of_WWI","ex:declares_wars_onTripleEntente","wasGeneratedBy(ex:beginning_of_WWI, ex:declares_wars_onTripleEntente, -)","gen"],["ex:Ferdinand","ex:AustriaHungary","actedOnBehalfOf(ex:Ferdinand, ex:AustriaHungary, ex:inspect_annexation)","del"],["ex:Princip","ex:Serbia","actedOnBehalfOf(ex:Princip, ex:Serbia, ex:assassinate_Ferdinand)","del"],["ex:assassinate_Ferdinand","ex:inspect_annexation","wasInformedBy(ex:assassinate_Ferdinand, ex:inspect_annexation)","wib"],["ex:send_message","ex:assassinate_Ferdinand","wasInformedBy(ex:send_message, ex:assassinate_Ferdinand)","wib"],["ex:declares_wars_onSerbia","ex:send_message","wasInformedBy(ex:declares_wars_onSerbia, ex:send_message)","wib"],["ex:declares_wars_onTripleEntente","ex:declares_wars_onSerbia","wasInformedBy(ex:declares_wars_onTripleEntente, ex:declares_wars_onSerbia)","wib"],["ex:send_message","ex:Germany","wasAssociatedWith(ex:send_message, ex:Germany, -)","waw"],["ex:assassinate_Ferdinand","ex:Ferdinand","wasAssociatedWith(ex:assassinate_Ferdinand, ex:Ferdinand, -)","waw"],["ex:send_message","ex:AustriaHungary","wasAssociatedWith(ex:send_message, ex:AustriaHungary, -)","waw"],["ex:support_from_germany","ex:TripleAllianceAgreement","wasDerivedFrom(ex:support_from_germany, ex:TripleAllianceAgreement, -, -, -)","der"],["ex:declares_wars_onTripleEntente","ex:support_from_germany","used(ex:declares_wars_onTripleEntente, ex:support_from_germany, -)","usd"],["ex:support_from_germany","ex:Germany","wasAttributedTo(ex:support_from_germany, ex:Germany)","att"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"src","type":"\"string\"","metadata":"{}"},{"name":"dst","type":"\"string\"","metadata":"{}"},{"name":"relation","type":"\"string\"","metadata":"{}"},{"name":"relation type","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>src</th><th>dst</th><th>relation</th><th>relation type</th></tr></thead><tbody><tr><td>ex:beginning_of_WWI</td><td>ex:declares_wars_onTripleEntente</td><td>wasGeneratedBy(ex:beginning_of_WWI, ex:declares_wars_onTripleEntente, -)</td><td>gen</td></tr><tr><td>ex:Ferdinand</td><td>ex:AustriaHungary</td><td>actedOnBehalfOf(ex:Ferdinand, ex:AustriaHungary, ex:inspect_annexation)</td><td>del</td></tr><tr><td>ex:Princip</td><td>ex:Serbia</td><td>actedOnBehalfOf(ex:Princip, ex:Serbia, ex:assassinate_Ferdinand)</td><td>del</td></tr><tr><td>ex:assassinate_Ferdinand</td><td>ex:inspect_annexation</td><td>wasInformedBy(ex:assassinate_Ferdinand, ex:inspect_annexation)</td><td>wib</td></tr><tr><td>ex:send_message</td><td>ex:assassinate_Ferdinand</td><td>wasInformedBy(ex:send_message, ex:assassinate_Ferdinand)</td><td>wib</td></tr><tr><td>ex:declares_wars_onSerbia</td><td>ex:send_message</td><td>wasInformedBy(ex:declares_wars_onSerbia, ex:send_message)</td><td>wib</td></tr><tr><td>ex:declares_wars_onTripleEntente</td><td>ex:declares_wars_onSerbia</td><td>wasInformedBy(ex:declares_wars_onTripleEntente, ex:declares_wars_onSerbia)</td><td>wib</td></tr><tr><td>ex:send_message</td><td>ex:Germany</td><td>wasAssociatedWith(ex:send_message, ex:Germany, -)</td><td>waw</td></tr><tr><td>ex:assassinate_Ferdinand</td><td>ex:Ferdinand</td><td>wasAssociatedWith(ex:assassinate_Ferdinand, ex:Ferdinand, -)</td><td>waw</td></tr><tr><td>ex:send_message</td><td>ex:AustriaHungary</td><td>wasAssociatedWith(ex:send_message, ex:AustriaHungary, -)</td><td>waw</td></tr><tr><td>ex:support_from_germany</td><td>ex:TripleAllianceAgreement</td><td>wasDerivedFrom(ex:support_from_germany, ex:TripleAllianceAgreement, -, -, -)</td><td>der</td></tr><tr><td>ex:declares_wars_onTripleEntente</td><td>ex:support_from_germany</td><td>used(ex:declares_wars_onTripleEntente, ex:support_from_germany, -)</td><td>usd</td></tr><tr><td>ex:support_from_germany</td><td>ex:Germany</td><td>wasAttributedTo(ex:support_from_germany, ex:Germany)</td><td>att</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We create several utilities function in order to help transform the algorithm to codes more easily"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53670c02-7772-4a32-a5eb-b41e7b8a7b2d"}}},{"cell_type":"code","source":["#We use this function to find the prov types of vertices\ndef getVTypeDict(g,primitive):\n  idList = [x[\"id\"]for x in g.vertices.rdd.collect()]\n  if primitive:\n    eleTypeList = [(x[\"type\"],x[\"primitive type\"])for x in g.vertices.rdd.collect()]\n  else:\n    eleTypeList = [x[\"type\"]for x in g.vertices.rdd.collect()]\n  return dict(zip(idList,eleTypeList))\n\n#same function as above but for edges\ndef getETypeDict(g):\n  edgeList =  [(x[\"src\"],x[\"dst\"])for x in g.edges.rdd.collect()]\n\n  typeList = [x[\"relation type\"]for x in g.edges.rdd.collect()]\n  return dict(zip(edgeList,typeList))\n\n#this function simply returns the prov types of all vertices which are essentially all the 0-types in this graph\ndef zeroType(g,primitive):\n  if primitive:\n    typeList = [(x[\"type\"],x[\"primitive type\"])for x in g.vertices.rdd.collect()]\n  else:\n    typeList = [x[\"type\"]for x in g.vertices.rdd.collect()]\n\n  return typeList\n\n#This function finds all the edges of 1 level that origin from a vertice. Then iterate the entire graph to find all the 1-types\ndef oneTypeDict(g,primitive):\n  relTypeList = [(x[\"relation type\"],x[\"src\"],x[\"dst\"])for x in g.edges.rdd.collect()]\n  VTypeDict = getVTypeDict(g,primitive)\n  srcDict = {}\n  for i in range(len(relTypeList)):\n    if relTypeList[i][1] not in srcDict.keys():\n      temp = []\n      temp.append([relTypeList[i][0],VTypeDict[relTypeList[i][2]]])\n      srcDict[relTypeList[i][1]] = temp\n    else:\n      temp = srcDict.get(relTypeList[i][1])\n      temp.append([relTypeList[i][0],VTypeDict[relTypeList[i][2]]])\n      srcDict[relTypeList[i][1]] = temp\n  return srcDict\n\n#this function \"opens\" a pairs and convert the elemnt within to prov types\ndef pairToType(listA,Vdict,Edict):\n      pairs = listA\n      zeroT = Vdict[pairs[-1][-1]]\n      for i in range(len(pairs)):\n        pairs[i]= Edict[pairs[i]]\n      pairs.append(zeroT)\n      return pairs\n\n#this function is used to remove duplicates for certain functions\ndef removeDuplicates(aList):\n  temp=[]\n  for x in aList:\n    if x not in temp:\n      temp.append(x)\n  return temp\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf2631fd-b175-4747-8cc2-e2235a0de773"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Here we utilize the utility functions we developed to create a general type-counting function."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beff71f2-d22c-4da6-add5-d12f2446a170"}}},{"cell_type":"code","source":["#this is the general function for all type counting\ndef typesCount(g,lvl,primitive,rmDuplicates):\n\n  #for level 0 and 1, since pair-matching algorithm starts iteration at level 2, level 0 and 1 are\n  # calculated with predefined functions imported from util.py\n  if lvl ==0:\n    return zeroType(g,primitive)\n  elif lvl ==1:\n    oneTypeRes = []\n    srcDict = oneTypeDict(g,primitive)\n    for value in srcDict.values():\n      oneTypeRes.append(value)\n\n\n    #remove duplicates options are different when primitive types are included\n    if rmDuplicates:\n      if primitive:\n        return removeDuplicates(oneTypeRes)\n      else:\n        return list(set(oneTypeRes))\n    else:\n       return oneTypeRes\n    \n  elif lvl<0:\n    print(\"error, level must not be a negative\")\n\n  #for all level higher than 1\n  else:\n    #we extracts all vertices ids and source and destination pairs of edges  from dataframes\n    allVertices = [x[\"id\"] for x in g.vertices.rdd.collect()]\n    allEdges= [(x[\"src\"],x[\"dst\"])for x in g.edges.rdd.collect()]\n    pair_list = []\n    types = []\n    VTypeDict = getVTypeDict(g,primitive)\n    ETypeDict = getETypeDict(g)\n\n    #creating a pairlist\n    for e in allEdges:\n\n      for e2 in allEdges:\n        if e2[0]==e[1]:\n          pair_list.append([e,e2])\n    pairListCopy =pair_list\n\n    #pair-matching\n    for h in range(lvl-1):\n      for p in pair_list:      \n          for cur in pairListCopy:\n            if (cur is None) or (p is None): \n              #print(\"error\")\n              pass\n            else:\n              lastE = p[-1]\n              firstE = cur[0]\n              if lastE == firstE:\n                #print(\"yay\")\n                pair_list.append(p.append(cur[1]))\n\n    for x in pair_list:\n      if x is None:\n        #print (\"\")\n        pass\n      else:\n        if len(x)==lvl:\n          types.append(x)\n\n    #creates mapping from pairs to prov types\n    provMap = dict((el,[]) for el in allVertices )\n    \n    for pair in types:\n      provMap[pair[0][0]].append(pairToType(pair,VTypeDict,ETypeDict))\n\n    for key,val in provMap.items():\n     \n      provMap[key] = removeDuplicates(provMap[key])\n      if len(provMap[key])>1:\n        \n        provMap[key]=list(zip(*provMap[key]))\n        \n    \n    allTypes = [x for x in list(provMap.values()) if x != []]\n      \n    return allTypes\n\ntypesCount(prov_to_graphframe(document),2,False,False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b64cab9-0739-4d97-825d-4da54ea01bbe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: [[[&#39;wib&#39;, &#39;wib&#39;, &#39;act&#39;]],\n [(&#39;usd&#39;, &#39;usd&#39;), (&#39;der&#39;, &#39;att&#39;), (&#39;ent&#39;, &#39;agt&#39;)],\n [[&#39;wib&#39;, &#39;waw&#39;, &#39;agt&#39;]],\n [[&#39;waw&#39;, &#39;del&#39;, &#39;agt&#39;]]]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: [[[&#39;wib&#39;, &#39;wib&#39;, &#39;act&#39;]],\n [(&#39;usd&#39;, &#39;usd&#39;), (&#39;der&#39;, &#39;att&#39;), (&#39;ent&#39;, &#39;agt&#39;)],\n [[&#39;wib&#39;, &#39;waw&#39;, &#39;agt&#39;]],\n [[&#39;waw&#39;, &#39;del&#39;, &#39;agt&#39;]]]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Upon the completion of counting provenance types, we want to summarize the list of results with each of their occurence included in a dictionary (feature vector)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f24640dc-b6a5-4af4-a01f-85b6093557a6"}}},{"cell_type":"code","source":["#this function summarizes all the prov types calculated in a feature vector (dictionary) with each type as key and occurences as value\ndef generateFeatVec(g,to_level,primitive):\n  rmDuplicates = False\n  featVecDict = {}\n  for i in range(to_level+1):\n    typesList=typesCount(g,i,primitive,rmDuplicates)\n    for fpt in typesList:\n      featVecDict[str(fpt)] = typesList.count(fpt)\n  return featVecDict\n\ngenerateFeatVec(g,2,False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb67493e-d9a2-40ad-9d2f-d18012ad6157"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[17]: {&#39;agt&#39;: 5,\n &#39;act&#39;: 5,\n &#39;ent&#39;: 3,\n &#34;[[&#39;gen&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[[&#39;del&#39;, &#39;agt&#39;]]&#34;: 2,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;waw&#39;, &#39;agt&#39;], [&#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;usd&#39;, &#39;ent&#39;]]&#34;: 1,\n &#34;[[&#39;der&#39;, &#39;ent&#39;], [&#39;att&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;wib&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[(&#39;usd&#39;, &#39;usd&#39;), (&#39;der&#39;, &#39;att&#39;), (&#39;ent&#39;, &#39;agt&#39;)]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;waw&#39;, &#39;del&#39;, &#39;agt&#39;]]&#34;: 1}</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: {&#39;agt&#39;: 5,\n &#39;act&#39;: 5,\n &#39;ent&#39;: 3,\n &#34;[[&#39;gen&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[[&#39;del&#39;, &#39;agt&#39;]]&#34;: 2,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;waw&#39;, &#39;agt&#39;], [&#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;act&#39;], [&#39;usd&#39;, &#39;ent&#39;]]&#34;: 1,\n &#34;[[&#39;der&#39;, &#39;ent&#39;], [&#39;att&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;wib&#39;, &#39;act&#39;]]&#34;: 1,\n &#34;[(&#39;usd&#39;, &#39;usd&#39;), (&#39;der&#39;, &#39;att&#39;), (&#39;ent&#39;, &#39;agt&#39;)]&#34;: 1,\n &#34;[[&#39;wib&#39;, &#39;waw&#39;, &#39;agt&#39;]]&#34;: 1,\n &#34;[[&#39;waw&#39;, &#39;del&#39;, &#39;agt&#39;]]&#34;: 1}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Benchmarking\nWe have been able to generate feature vectors usable to assemble the sparse matrix.\nHere we do a little bit of benchmarking to evaluate the runtime of our functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0381531e-6ac2-437b-8d27-fd98b8c7c77d"}}},{"cell_type":"code","source":["def benchmarkingP(document):\n    fv = [] #feature vector generation runtime results\n    tcp = [] #type counting processes runtime results\n    tc = [] #type counting(on pre-generated graph) runtime results\n    # loop 5 times and find average value\n    for i in range(5):\n        start = time.perf_counter()\n        generateFeatVec(prov_to_graphframe(document),2,False)\n        end = time.perf_counter()\n        fv.append(end - start)\n\n        start = time.perf_counter()\n        typesCount(prov_to_graphframe(document),2,False,False)\n        end = time.perf_counter()\n        tcp.append(end - start)\n\n        g = prov_to_graphframe(document)\n        start = time.perf_counter()\n        typesCount(g,2,False,False)\n        end = time.perf_counter()\n        tc.append(end - start)\n    fvtime = sum(fv) / len(fv)\n    tcptime = sum(tcp) / len(tcp)\n    tctime = sum(tc) / len(tc)\n    print(fvtime)\n    print(tcptime)\n    print(tctime)\n    plt.bar([\"feature vector generation\",\"type-counting\", \"pre-converted type-counting\"],[fvtime / tctime, tcptime / tctime, tctime / tctime])\n\nbenchmarkingP(document)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8912bfbd-4350-4946-9cc2-b8d1394b79c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0.9228574570000092\n0.6273185836000266\n0.546591633800017\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9228574570000092\n0.6273185836000266\n0.546591633800017\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/60cba0ff-0ddb-4896-864e-269168a64c13.png","removedWidgets":[],"addedWidgets":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"markdown","source":["#Reproducing experiements data\nFrom here on we have finished our demonstration of pair-matching type-counting on one PROV file. If you like to reproduce the data we have used in our research. datasets should be dowloaded from https://github.com/trungdong/provenance-kernel-evaluation and uploaded to the DBFS manually. \nYou're also more than welcome to try the same experiements on your own datasets, but they have to be uploded to the DBFS manually as well."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40d3a3fa-bbda-4b03-8e49-b90a4b04adb3"}}},{"cell_type":"markdown","source":["From here, we'll start by creating some data processing functions to extract data from the datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4ed2460-1038-419a-905b-2932bb55856c"}}},{"cell_type":"code","source":["def formatFileName(f):\n  f= f.replace(\".json\",\"\")\n  f=f.replace(\".\",\"_\")\n  f=f.replace(\"-\",\"_\")\n  f = f+\".json\"\n  return f\ndef csv_procs(f,path):\n  csv_data = path + \"/\" +\"graphs.csv\"\n  df = pd.read_csv(csv_data)\n  csv_data = dict(zip(list(df.graph_file), list(df.label)))\n  return csv_data[f]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e42d41f-428a-400f-8435-9c31f5e41430"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Then we will use all the functions we have created so far to define a sparse matrix creation function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70b4e08f-48b9-4c14-87db-9e505bf266ab"}}},{"cell_type":"code","source":["\ndef createSparseMtxSpark(filenames,path,lvl,primitive):\n    csv_data = path + \"/\" +\"graphs.csv\"\n    df = pd.read_csv(csv_data)\n    df['graph_file'] = df['graph_file'].apply(lambda x: formatFileName(x))\n    csv_dict = dict(zip(list(df.graph_file), list(df.label)))\n    \n    prov_list = [(ProvDocument.deserialize(path+\"/\"+f),csv_dict[f])for f in filenames]\n    featVecsList = []\n    for doc in prov_list:\n      featVecs = generateFeatVec(prov_to_graphframe(doc[0]),lvl,primitive) \n      featVecs[\"label\"] = doc[1]\n      featVecsList.append(featVecs)\n      \n    \n    df = sc.parallelize(featVecsList).toDF()\n    \n\n    return df\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8eb7194-9a0c-4b48-97cf-1a7e81a467a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'll then create all the training data we needed by generating sparse matrix for each datasets as orc files(which can be processed by Spark DataFrames later on)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e8ea23a-cb9a-4ca7-a21d-6d2e01873e28"}}},{"cell_type":"code","source":["def generateOrcFile(path,lvl,primitive):\n  filenames=os.listdir(path)\n  jsonfilenames = [f for f in filenames if f.endswith(\".json\")]\n  X=createSparseMtxSpark(jsonfilenames,path,lvl,primitive)\n  X = X.na.fill(value=0)\n  return X"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f97f030-db1b-48c6-90ba-bd7ca05bbfe0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We will then use this function to generate results for our training data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82ce3ec1-9a26-45d8-adda-793a317ba879"}}},{"cell_type":"markdown","source":["**Warn that this process can take extremely long with large datasets since our development of Spark-based provenacne kernel is still at beta-stage. The datasets we use for our experiements are significantly large. Depends on your cluster, the process could take from half an hour to more than 6 hours.**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fa9953c-8868-4559-8ceb-4fc589f75672"}}},{"cell_type":"markdown","source":["**Note:** If you simply like to see the results generated from the machine learning. You can go to our Provenance Kernel Machine Learning notebook and upload the orc files we provided. It will save a significant amount of time if you only intend to reproduce machine learning results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0188e340-a143-4d68-b621-9d0b1af09ec1"}}},{"cell_type":"code","source":["#please comment out below line and define your own main path for your datasets directory\nmainpath = \"/dbfs/FileStore/shared_uploads/jian.1.huang@kcl.ac.uk/provSpark-datasets\"\n########################################################################################\n\n#please also change below list according to your DBFS paths if you use different datasets\ndirList = {\"/CM-Routes\",\n            \"/CM-RouteSets\",\n            \"/CM-Buildings\",\n            \"/PG-D\",\n            \"/PG-T\"\n            }\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44c06e97-4944-4427-b90f-7c1b30b5ab3a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Every dataset is trained with two kernels: one that include PROV-primitive types and one that only include PROV-generic types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14e28441-b603-4a59-ace4-3c9e412074b5"}}},{"cell_type":"code","source":["for path in dirList:\n  X_primitive = generateOrcFile(mainpath+path,2,True)\n\n  X_primitive.write.format(\"orc\").save(mainpath+path+\"P\"+\".orc\")\n  \n  X_not_primitive = generateOrcFile(mainpath+path,2,False)\n\n  X_not_primitive.write.format(\"orc\").save(mainpath+path+\"NP\"+\".orc\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6024edb-2d7f-4115-86ac-fd903249dc59"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We will take a look of our sparse matrix here to verify it has been successfully generated"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8859b26-2403-4aa1-b0d5-011ef32dda16"}}},{"cell_type":"code","source":["spark.read.orc(mainpath+dirList[0]+\"NP\"+\".orc\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf3c7350-bb98-49b0-be96-fd909bf94590"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["run below cells if you want to save your results as csv files"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"520bd30d-4ab5-4a34-871e-1da15c3966df"}}},{"cell_type":"code","source":["for dataset in dataset_proper_names:\n  sample = spark.read.orc(mainpath+\"/\"+dataset+\".orc\")\n  sample.toPandas().to_csv(mainpath+\"/generatedData/\"+dataset+\".csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f575abb-a428-42e0-8642-355db5f9c233"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"provspark-pair-matching","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":28}},"nbformat":4,"nbformat_minor":0}
